{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10807273-673f-4a64-a35b-6984c2fc4f6e",
   "metadata": {},
   "source": [
    "# LLM experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f64ffa-603f-4d1a-af3d-f84e7369e221",
   "metadata": {},
   "source": [
    "Select the cells below by clicking on them. Press `Shift+Enter` to run the cell contents and advance to the next cell, or press the Play button in the toolbar above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efb22e9-dfee-4b46-8f7f-02711f636a97",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dce45f-05fe-45ee-a811-d5d598f745fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat import Chatbot  # see chat.py in this folder\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e836c6-9cc4-4ceb-85ed-2d3079244d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device and dtype\n",
    "%run platform_settings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011844e7-6d29-4cf8-91e2-72ba7f268318",
   "metadata": {},
   "source": [
    "## Create a HuggingFace `pipeline` object\n",
    "\n",
    "The `pipeline` is a class which handles processing the text to feed to the LLM, and reads the output back into natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9a34a-0e76-4390-a907-5576285c0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
    "REVISION = \"77e23968eed12d195bd46c519aa679cc22a27ddc\"  # reference commit 77e2396 from the above repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ae6fa-c6c9-4c9c-aae6-39cc772dae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",  # sets up tokenizer and pre-processor\n",
    "    model=MODEL,  # https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
    "    revision=REVISION,  # reference commit 77e2396 from the above repo\n",
    "    torch_dtype=dtype,  # defined from platform_settings.py\n",
    "    device=device,  # defined from platform_settings.py\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d4f30-62c3-4cf2-b814-6f50ee8c4d3b",
   "metadata": {},
   "source": [
    "## Create a `Chatbot` based on `pipe`\n",
    "\n",
    "The `Chatbot` class (defined in [chat.py](./chat.py)) send user messages to the LLM using the `pipeline` we created earlier (named `pipe`) as part of a chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08461d5-6ce7-4740-99b7-4b88e04257a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Chatbot\n",
    "\n",
    "bot = Chatbot(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7a074-ad37-4ddb-914e-e44d06d45cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new chat. You can specify a system prompt here, which controls how the LLM will respond.\n",
    "\n",
    "bot.start_new_chat(system_prompt=\"You are a helpful chatbot assistant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484156c4-02fe-4fe7-b3f7-c7cb548fdd7f",
   "metadata": {},
   "source": [
    "### Talk to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b415c2-961e-47a8-b06b-3554b7525051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test math knowledge\n",
    "\n",
    "bot.send_user_chat_message(\"What's the square root of 49?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4da55c-7823-47b3-abe0-497e69acdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try some geography knowledge too\n",
    "\n",
    "bot.send_user_chat_message(\"Let's try geography - what is the capital of Uzbekistan?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14f7db-4d7b-4f47-a2cb-9bdfd002744b",
   "metadata": {},
   "source": [
    "## Try other models!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d77a889-a778-4ce8-a0b6-cb2a55573c8f",
   "metadata": {},
   "source": [
    "Check out other models at https://huggingface.co/models?pipeline_tag=text-generation&sort=trending, and replace the `MODEL` and `REVISION` variables in the code cell below.\n",
    "\n",
    "* The `MODEL` is just the title of the card (like `mistralai/Mixtral-8x7b-Instruct-v0.1`).\n",
    "* The `REVISION` is the git commit hash of the model version to use. Click the card, go to \"Files and versions\" tab, click \"History: X commits\" along the right, and copy the commit hash of the version you want to use.\n",
    "\n",
    "![model_version.png](model_version.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3746ac3-c643-4e83-b761-b4722bc88601",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = ...\n",
    "REVISION = ...\n",
    "\n",
    "# Create the HuggingFace Transformers pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=MODEL,\n",
    "    revision=REVISION,\n",
    "    torch_dtype=dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Create a new Chatbot based on the new model\n",
    "bot = Chatbot(pipe)\n",
    "\n",
    "# See how it does!\n",
    "bot.start_new_chat(system_prompt=\"You are a helpful chatbot assistant.\")\n",
    "\n",
    "bot.send_user_chat_message(\"What's the square root of 49?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b376dc-91e4-4829-b712-2cd0d8b627ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
